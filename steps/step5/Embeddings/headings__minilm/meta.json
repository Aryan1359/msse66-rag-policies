[
  {
    "doc_id": "etops_5503_50605121425",
    "chunk_id": 0,
    "source_file": "etops_5503_50605121425.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "8c26dbded11e6ebf7f4fe83889e73c6b80ec2e2bc81f7894e95c4b362e18fc6f",
    "text": "Boeing Pilots\nFlight Training Bulletin\n\nRevision Cycle 2 Updates\n\nFlight Ops Division ‚îÇ 6/5/25",
    "vector_index": 0
  },
  {
    "doc_id": "etops_5503_50605121425",
    "chunk_id": 1,
    "source_file": "etops_5503_50605121425.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "8c26dbded11e6ebf7f4fe83889e73c6b80ec2e2bc81f7894e95c4b362e18fc6f",
    "text": "For supplemental information please review the following RC2 Updates:\n\nETOPS 1. Preflight Procedures\n\nETOPS 2. Enroute Procedures\n\nBefore Start - CA\n\nRC2 ‚Äì Training Highlights Podcast\n\nYou can also find these videos and podcast on Alaska Pilot Training App.\n\nThank you,\n\nYour Flight Training Team\n\nPage | 1",
    "vector_index": 1
  },
  {
    "doc_id": "hydropower_formula_live_demo_html",
    "chunk_id": 0,
    "source_file": "hydropower_formula_live_demo_html.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "40862dae9118cc2b94afe88f5a2cd1742c8ed0ef86d400f05586e6b300bc0275",
    "text": "Hydropower Formula ‚Äì Live Demo\n\nHydropower Formula ‚Äì Live Demo\n\nInteractive calculator for\nP\n =\nŒ∑\n ¬∑ œÅ ¬∑ g ¬∑\nQ\n ¬∑\nh\n (all SI units). Adjust inputs and see power update instantly.\n\nInputs\n\nEfficiency Œ∑\n\nFlow rate Q\n(m3/s)\n\nHead h\n(m)\n\nAdvanced (density œÅ and gravity g)\n\nDensity œÅ\n(kg/m3)\n\nGravity g\n(m/s2)\n\nReset\n\nThree Gorges example\n\nUnits: SI (W, m, m3/s)\n\nOutput",
    "vector_index": 2
  },
  {
    "doc_id": "hydropower_formula_live_demo_html",
    "chunk_id": 1,
    "source_file": "hydropower_formula_live_demo_html.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "40862dae9118cc2b94afe88f5a2cd1742c8ed0ef86d400f05586e6b300bc0275",
    "text": "‚Äî MW\n\nP = Œ∑¬∑œÅ¬∑g¬∑Q¬∑h = ‚Äî W\n\nScale reference: bar fills at 25 GW\n\nPer‚Äêm3 energy and intuition\n\nQuantity\nExpression\nValue\n\nEnergy per m3 of water (at head h)\nE/m3 = œÅ¬∑g¬∑h\n‚Äî J/m3\n\nPower per (m3/s) of flow\nP/(m3/s) = Œ∑¬∑œÅ¬∑g¬∑h\n‚Äî W per (m3/s)\n\nShow full breakdown\n\nŒ∑ (efficiency)\n‚Äî\n\nœÅ (kg/m3)\n‚Äî\n\ng (m/s2)\n‚Äî\n\nQ (m3/s)\n‚Äî\n\nh (m)\n‚Äî\n\nProduct Œ∑¬∑œÅ¬∑g¬∑Q¬∑h\n‚Äî",
    "vector_index": 3
  },
  {
    "doc_id": "hydropower_formula_live_demo_html",
    "chunk_id": 2,
    "source_file": "hydropower_formula_live_demo_html.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "40862dae9118cc2b94afe88f5a2cd1742c8ed0ef86d400f05586e6b300bc0275",
    "text": "Nearest MW:\n‚Äî",
    "vector_index": 4
  },
  {
    "doc_id": "hydropower_formula_live_demo_html",
    "chunk_id": 3,
    "source_file": "hydropower_formula_live_demo_html.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "40862dae9118cc2b94afe88f5a2cd1742c8ed0ef86d400f05586e6b300bc0275",
    "text": "Also:",
    "vector_index": 5
  },
  {
    "doc_id": "hydropower_formula_live_demo_html",
    "chunk_id": 4,
    "source_file": "hydropower_formula_live_demo_html.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "40862dae9118cc2b94afe88f5a2cd1742c8ed0ef86d400f05586e6b300bc0275",
    "text": "‚Äî GW\n\nHow to talk about it in your presentation\n\nP\n (power) grows when either the drop is taller (\nh\n increases) or more water moves each second (\nQ\n increases). The constant terms œÅ (water density) and g (gravity) turn height into energy, and Œ∑ captures real‚Äêworld losses in the turbine/generator. Together:\nP = Œ∑¬∑œÅ¬∑g¬∑Q¬∑h\n.\n\nUse the sliders live while presenting to show how doubling\nQ\n doubles power, or how raising\nh\n boosts power linearly.\n\nOpen ‚ÄúAdvanced‚Äù to explain why we typically fix œÅ‚âà1000 kg/m3 and g‚âà9.81 m/s2.\n\nQuote the ‚ÄúPower per (m3/s)‚Äù number to make quick mental math: each extra m3/s of flow adds that many Watts at your chosen head and Œ∑.",
    "vector_index": 6
  },
  {
    "doc_id": "readme",
    "chunk_id": 0,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# MSSE66 RAG ‚Äî Company Policies Q&A\n\nRetrieval‚ÄêAugmented Generation (RAG) app that answers questions about a small corpus of **company policies**. Built as part of the **MSSE66+ AI Engineering Project** and aligned to the rubric (env + CI, ingestion, retrieval, deploy, evaluation).",
    "vector_index": 7
  },
  {
    "doc_id": "readme",
    "chunk_id": 1,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 8
  },
  {
    "doc_id": "readme",
    "chunk_id": 2,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üìå Status (end of Phase 2)\n\n**Done:**\n\n* Repo + Codespaces, `.venv`, Python pinned (3.12.1 via `.python-version`, `runtime.txt`)\n* Minimal deps: `Flask`, `python-dotenv`\n* Flask endpoints: `/` and `/health`\n* CI: `.github/workflows/ci.yml` smoke‚Äêtests `import app`\n* Corpus: `data/policies/*.md` (PTO, Expenses, Remote Work)",
    "vector_index": 9
  },
  {
    "doc_id": "readme",
    "chunk_id": 3,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "* Ingestion & Indexing scripts:\n\n  * `scripts/ingest.py` ‚Üí doc stats\n  * `scripts/chunk.py` ‚Üí overlapping chunks\n  * `scripts/index_jsonl.py` ‚Üí writes `data/index/policies.jsonl`\n  * `scripts/search_jsonl.py` ‚Üí tiny keyword search (CLI)\n* API: `/search?q=...&topk=...` returns keyword‚Äêmatched chunks (JSON)\n\n**Next:** Phase 3 (Embeddings + vector search) ‚Üí Phase 4 (UI) ‚Üí Phase 5 (Deploy) ‚Üí Phase 6 (Eval)",
    "vector_index": 10
  },
  {
    "doc_id": "readme",
    "chunk_id": 4,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 11
  },
  {
    "doc_id": "readme",
    "chunk_id": 5,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üöÄ Quickstart (GitHub Codespaces)\n\n```bash",
    "vector_index": 12
  },
  {
    "doc_id": "readme",
    "chunk_id": 6,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# 1) Activate the virtualenv\nsource .venv/bin/activate",
    "vector_index": 13
  },
  {
    "doc_id": "readme",
    "chunk_id": 7,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# 2) (Re)build JSONL index if you changed policies\npython scripts/index_jsonl.py",
    "vector_index": 14
  },
  {
    "doc_id": "readme",
    "chunk_id": 8,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# 3) Run the app (serves on port 8000)\npython app.py\n```\n\n**Test locally from the terminal inside Codespaces:**\n\n```bash",
    "vector_index": 15
  },
  {
    "doc_id": "readme",
    "chunk_id": 9,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# Health\ncurl \"http://127.0.0.1:8000/health\"",
    "vector_index": 16
  },
  {
    "doc_id": "readme",
    "chunk_id": 10,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# Keyword search\ncurl \"http://127.0.0.1:8000/search?q=pto%20accrual&topk=3\"\n```\n\n> In the browser, use your **forwarded URL** (looks like `https://<id>-8000.app.github.dev/`). In the terminal, prefer `http://127.0.0.1:8000`.",
    "vector_index": 17
  },
  {
    "doc_id": "readme",
    "chunk_id": 11,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 18
  },
  {
    "doc_id": "readme",
    "chunk_id": 12,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üß© What‚Äôs implemented (Phase 2)\n\n* **Corpus** in `data/policies/`: small, legal‚Äêto‚Äêuse Markdown files.\n* **Loader (`scripts/ingest.py`)** prints words/lines/headings per file.\n* **Chunker (`scripts/chunk.py`)** creates ~600‚Äêchar chunks with ~100‚Äêchar overlap, preferring breaks on blank lines/headings.\n* **Index writer (`scripts/index_jsonl.py`)** emits one JSON object per chunk to `data/index/policies.jsonl` with ids, text, and rough token counts.\n* **Keyword search (CLI)** scores by simple term frequencies with word boundaries.\n* **Flask `/search`** mirrors the CLI search and returns top‚Äêk results with previews and metadata.",
    "vector_index": 19
  },
  {
    "doc_id": "readme",
    "chunk_id": 13,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 20
  },
  {
    "doc_id": "readme",
    "chunk_id": 14,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üìÅ Repository Structure\n\n```\nmsse66-rag-policies/\n‚îú‚îÄ app.py                          # Flask app with /, /health, /search\n‚îú‚îÄ data/\n‚îÇ  ‚îú‚îÄ policies/                    # Policy corpus (Markdown)\n‚îÇ  ‚îÇ  ‚îú‚îÄ 01-pto.md\n‚îÇ  ‚îÇ  ‚îú‚îÄ 02-expenses.md\n‚îÇ  ‚îÇ  ‚îî‚îÄ 03-remote-work.md\n‚îÇ  ‚îî‚îÄ index/\n‚îÇ     ‚îî‚îÄ policies.jsonl            # Generated JSONL index (build via scripts)\n‚îú‚îÄ scripts/\n‚îÇ  ‚îú‚îÄ ingest.py                    # Corpus stats\n‚îÇ  ‚îú‚îÄ chunk.py                     # Overlapping chunker\n‚îÇ  ‚îú‚îÄ index_jsonl.py               # Write JSONL index\n‚îÇ  ‚îî‚îÄ search_jsonl.py              # CLI keyword search over JSONL\n‚îú‚îÄ .github/workflows/ci.yml        # CI: install deps + smoke test\n‚îú‚îÄ requirements.txt\n‚îú‚îÄ .python-version\n‚îú‚îÄ runtime.txt\n‚îú‚îÄ Instruction.md                  # Mentor/working-mode instructions\n‚îú‚îÄ LEARNING-GUIDE.md               # Beginner guide (what/why/how)\n‚îú‚îÄ checklist.md                    # Master checklist (rubric aligned)\n‚îî‚îÄ PROGRESS-LOG.md                 # Chronological log\n```",
    "vector_index": 21
  },
  {
    "doc_id": "readme",
    "chunk_id": 15,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 22
  },
  {
    "doc_id": "readme",
    "chunk_id": 16,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üîÑ Branch / PR Workflow (beginner‚Äêproof)\n\n1. Create a feature branch: `git checkout -b <feature>`\n2. Make a tiny change; verify locally\n3. `git add ... && git commit -m \"<scope>: <message>\"`\n4. `git push -u origin <feature>` ‚Üí Open PR ‚Üí Merge ‚Üí Delete branch\n5. Sync: `git checkout main && git pull`",
    "vector_index": 23
  },
  {
    "doc_id": "readme",
    "chunk_id": 17,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 24
  },
  {
    "doc_id": "readme",
    "chunk_id": 18,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üß™ Verification Cheatsheet\n\n```bash",
    "vector_index": 25
  },
  {
    "doc_id": "readme",
    "chunk_id": 19,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# Stats\npython scripts/ingest.py",
    "vector_index": 26
  },
  {
    "doc_id": "readme",
    "chunk_id": 20,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# Chunking\npython scripts/chunk.py",
    "vector_index": 27
  },
  {
    "doc_id": "readme",
    "chunk_id": 21,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# Index build\npython scripts/index_jsonl.py && wc -l data/index/policies.jsonl",
    "vector_index": 28
  },
  {
    "doc_id": "readme",
    "chunk_id": 22,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# CLI search\npython scripts/search_jsonl.py \"pto accrual\" --topk 3",
    "vector_index": 29
  },
  {
    "doc_id": "readme",
    "chunk_id": 23,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "# API search\ncurl \"http://127.0.0.1:8000/search?q=pto%20accrual&topk=3\"\n```",
    "vector_index": 30
  },
  {
    "doc_id": "readme",
    "chunk_id": 24,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 31
  },
  {
    "doc_id": "readme",
    "chunk_id": 25,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üß≠ Roadmap (Phases 3‚Äì6)\n\n**Phase 3 ‚Äî Embeddings & Vector Search**\n\n* Choose embeddings: local (`sentence-transformers`) vs API provider\n* `scripts/embed_index.py` ‚Üí create vectors (e.g., `.npy` + `meta.json`)\n* `scripts/vector_search.py` ‚Üí cosine similarity top‚Äêk\n* Extend Flask `/search?mode=vector` with citations (doc_id + chunk_id)\n\n**Phase 4 ‚Äî Web UI**\n\n* Minimal search page calling `/search`\n* Display sources + highlighted snippets\n\n**Phase 5 ‚Äî Deployment & CI/CD**\n\n* Deploy on Render/Railway (free tier)\n* GH Actions: deploy on `main`\n\n**Phase 6 ‚Äî Evaluation**\n\n* 15‚Äì30 Q/A set over policies\n* Metrics: groundedness, citation accuracy, latency (p50/p95)\n* Report in `design-and-evaluation.md`",
    "vector_index": 32
  },
  {
    "doc_id": "readme",
    "chunk_id": 26,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 33
  },
  {
    "doc_id": "readme",
    "chunk_id": 27,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## üõ†Ô∏è Troubleshooting\n\n* `ModuleNotFoundError: flask` ‚Üí `source .venv/bin/activate`\n* 404 on `/search` ‚Üí ensure route is defined **before** `app.run(...)`; restart server\n* `curl` to `app.github.dev` shows nothing ‚Üí test via `http://127.0.0.1:8000` inside terminal",
    "vector_index": 34
  },
  {
    "doc_id": "readme",
    "chunk_id": 28,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---",
    "vector_index": 35
  },
  {
    "doc_id": "readme",
    "chunk_id": 29,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "## ü§ñ AI Use & CI Disclosure\n\n* AI helpers: **ChatGPT‚Äê5** (mentor/co‚Äêdev) + optional **GitHub Copilot**\n* CI: runs on each push/PR, installs deps, smoke‚Äêtests `import app`",
    "vector_index": 36
  },
  {
    "doc_id": "readme",
    "chunk_id": 30,
    "source_file": "readme.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "9607a006be055e9810b0d44f36c3146b50251484d24d1b2e0c9325a82c283e3e",
    "text": "---\n\n**Maintainer:** Aryan Yaghobi\n**Mentor / AI Co‚ÄêDeveloper:** ChatGPT‚Äê5\n\n> This README documents Phase 2 completion and provides clear run steps, verification, and a rubric‚Äêaligned roadmap.",
    "vector_index": 37
  },
  {
    "doc_id": "rubric",
    "chunk_id": 0,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "AI\nEngineering\nProject\n\nProject Overview\n\nFor this project, you will be designing, building, and evaluating a Retrieval-Augmented\nGeneration (RAG) LLM-based application that answers user questions about a corpus of\ncompany policies & procedures. You will then deploy the application to a free-tier host\n(e.g., Render, Railway) with a basic CI/CD pipeline (e.g., GitHub Actions) that triggers\ndeployment on push/PR when the app builds successfully. Finally, you will demonstrate\nthe system via a screen-share video showing key features of your deployed application,\nand a quick walkthrough of your design, evaluation and CI/CD run. You can complete this\nproject either individually or as a group of no more than three people.\n\nWhile you can fully hand code this project if you wish, you are highly encouraged to\nutilize leading AI code generation models/AI IDEs/async agents to assist in rapidly\nproducing your solution, being sure to describe in broad terms how you made use of\nthem. Here are some examples of very useful AI tools you may wish to consider. You will\nbe graded on the quality and functionality of the application and how well it meets the\nproject requirements‚Äîno given proportion of the code is required to be hand coded.\n\nLearning Outcomes",
    "vector_index": 38
  },
  {
    "doc_id": "rubric",
    "chunk_id": 1,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "When completed successfully, this project will enable you to:\n\n‚óè  Demonstrate excellent AI engineering skills\n‚óè  Demonstrate the ability to select appropriate AI application design and\n\narchitecture\nImplement a working LLM-based application including RAG\n\n‚óè\n‚óè  Evaluate the performance of an LLM-based application\n‚óè  Utilize AI tooling as appropriate\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21\n\n\n\n\n\n\n\n\nAI Engineering Project\n\nProject Description\n\nFirst, assemble a small but coherent corpus of documents outlining company policies &\nprocedures - about 5‚Äì20 short markdown/HTML/PDF/TXT files totaling 30‚Äì120 pages.\nYou may author them yourself (with AI assistance) or use policies that you are aware of\nfrom your own organization that can be used for this assignment. Students must use a\ncorpus they can legally include in the repo or load at runtime (e.g., your own synthetic\npolicies, your organization‚Äôs employee policy documents etc.)‚Äîno private/paid data is\nrequired. Additionally, you should define success metrics for your application (see the\n‚ÄúEvaluation‚Äù step below), including at least one information-quality metric (e.g.,\ngroundedness or citation accuracy) and one system metric (e.g., latency).\n\nUse free or zero-cost options when possible e.g., OpenRouter‚Äôs free tier\n(https://openrouter.ai/docs/api-reference/limits), Groq\n(https://console.groq.com/docs/rate-limits), or your own paid API keys if you have them.\nFor embedding models, free-tier options are available from Cohere, Voyage,\nHuggingFace and others\n\nComplete the following steps to fully develop, deploy, and evaluate your application:\n\n1.  Environment and Reproducibility\n\n‚óã  Create a virtual environment (e.g., venv, conda).\n‚óã  List dependencies in requirements.txt (or environment.yml).\n‚óã  Provide a README.md with setup + run instructions.\n‚óã  Set fixed seeds where/if applicable (for deterministic chunking or\n\nevaluation sampling).\n\n2.  Ingestion and Indexing\n\n‚óã  Parse & clean documents (handle PDFs/HTML/md/txt).\n‚óã  Chunk documents (e.g., by headings or token windows with overlap).\n‚óã  Embed chunks with a free embedding model or a free-tier API.\n‚óã  Store the embedded document chunks in a local or lightweight vector\ndatabase (e.g. Chroma or optionally a cloud-hosted vector store like\nPinecone, etc.)\n\n‚óã  Store vectors in a local/vector DB or cloud DB (e.g., Chroma, Pinecone, etc.)\n\n3.  Retrieval and Generation (RAG)\n\n‚óã  To build your RAG pipeline you may use frameworks such as LangChain to\n\nhandle retrieval, prompt chaining, and API calls, or implement these\nmanually.\nImplement Top-k retrieval with optional re-ranking.\n\n‚óã\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21                                        2\n\n\n\n\nAI Engineering Project\n\n‚óã  Build a prompting strategy that injects retrieved chunks (and\n\ncitations/sources) into the LLM context.",
    "vector_index": 39
  },
  {
    "doc_id": "rubric",
    "chunk_id": 2,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óã  Add basic guardrails:\n\n‚ñ†  Refuse to answer outside the corpus (‚ÄúI can only answer about our\n\npolicies‚Äù),\n\n‚ñ†  Limit output length,\n‚ñ†  Always cite source doc IDs/titles for answers.\n\n4.  Web Application\n\n‚óã  Students can use Flask, Streamlit or alternative for the Web app. LangChain\n\nis recommended for orchestration, but is optional.",
    "vector_index": 40
  },
  {
    "doc_id": "rubric",
    "chunk_id": 3,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óã  Endpoints/UI:\n‚ñ†\n‚ñ†\n\n/   - Web chat interface - text box for user input\n/chat - API endpoint that receives user questions (POST) and returns\nmodel-generated answers with citations and snippets (link to source\nand show snippet).\n/health - returns simple status via JSON.\n\n‚ñ†\n5.  Deployment\n\n‚óã  For production hosting use Render or Railway free tiers; students may\n\nalternatively use any other free-tier providers of their choice.\n\n‚óã  Configure environment variables (e.g. API keys, model endpoints, DB\n\nrelated etc.).\n\n‚óã  Ensure the app is publicly accessible at a shareable URL.",
    "vector_index": 41
  },
  {
    "doc_id": "rubric",
    "chunk_id": 4,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "6.  CI/CD\n\n‚óã  Minimal automated testing is sufficient for this assignment (a build/run\n\ncheck, optional smoke test).",
    "vector_index": 42
  },
  {
    "doc_id": "rubric",
    "chunk_id": 5,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óã  Create a GitHub Actions workflow that on push/PR:\n\nInstalls dependencies,\n\n‚ñ†\n‚ñ†  Runs a build/start check (e.g., python -m pip install -r\n\nrequirements.txt and python -c \"import app\" or pytest -q if you add\ntests),\n\n‚ñ†  On success in main, deploy to your host (Render/Railway action or\n\nvia webhook/API).\n\n7.  Evaluation of the LLM Application\n\n‚óã  Provide a small evaluation set of 15‚Äì30 questions covering various policy",
    "vector_index": 43
  },
  {
    "doc_id": "rubric",
    "chunk_id": 6,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "topics (PTO, security, expense, remote work, holidays, etc.). Report:",
    "vector_index": 44
  },
  {
    "doc_id": "rubric",
    "chunk_id": 7,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚ñ†  Answer Quality (required):\n\n1.  Groundedness: % of answers whose content is factually\nconsistent with and fully supported by the retrieved\nevidence‚Äîi.e., the answer contains no information that is\nabsent or contradicted in the context.\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21                                        3\n\n\n\nAI Engineering Project\n\n2.  Citation Accuracy: % of answers whose listed citations\n\ncorrectly point to the specific passage(s) that support the\ninformation stated‚Äîi.e., the attribution is correct and not\nmisleading.\n\n3.  Exact/Partial Match (optional): % of answers that exactly or\n\npartially match a short gold answer you provide.",
    "vector_index": 45
  },
  {
    "doc_id": "rubric",
    "chunk_id": 8,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚ñ†  System Metrics (required):\n\n1.  Latency (p50/p95) from request to answer for 10‚Äì20 queries.\n\n‚ñ†  Ablations (optional): compare retrieval k, chunk size, or prompt\n\nvariants.\n8.  Design Documentation\n\n‚óã  Briefly justify design choices (embedding model, chunking, k, prompt\n\nformat, vector store).\n\nSubmission Guidelines",
    "vector_index": 46
  },
  {
    "doc_id": "rubric",
    "chunk_id": 9,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "Your final submission should consist of two links:\n\n‚óè  A link to an accessible software repository (a GitHub repo) containing all your\n\ndeveloped code and the items listed below. You must share your repository with\nthe GitHub account, quantic-grader.\n\no  The GitHub repository should include a link to the deployed version of\n\nyour RAG LLM-based application (in file deployed.md)\n\no  The GitHub repository must include a README.md file indicating setup and\n\nrun instructions\n\no  The GitHub repository must also include a brief design and evaluation",
    "vector_index": 47
  },
  {
    "doc_id": "rubric",
    "chunk_id": 10,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "document (design-and-evaluation.md) listing and explaining:\n\ni)\n\nii)\n\ndesign and architecture decisions made - and why they were made,\nincluding technology choices\nsummary of your evaluation approach and results for your RAG\nsystem\n\no  The GitHub repository must include an ai-use.md file that briefly describes\n\nwhich AI code tools you used and how.\n\n‚óè  A link to a recorded screen-share demonstration video of the working RAG\n\nLLM-based application, involving screen capture of it being used with voiceover\n\no  All group members must speak and be present on camera.\no  All group members must show their government ID.\no  The demonstration/presentation should be between 5 and 10 minutes long.\n\nTo submit your project, please click on the \"Submit Project\" button on your dashboard\nand follow the steps provided. If you are submitting your project as a group, please\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21                                        4\n\n\n\n\nAI Engineering Project\n\nProject Rubric\n\nScores 2 and above are considered passing. Students who receive a 1 or 0 will not get\ncredit for the assignment and must revise and resubmit to receive a passing grade.\n\nScore\n\nDescription\n\n5",
    "vector_index": 48
  },
  {
    "doc_id": "rubric",
    "chunk_id": 11,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óè  Addresses ALL of the project requirements, but not limited to:\n\n‚óã  Outstanding RAG application with correct responses with matching\n\ncitations, ingest and indexing works\n\n‚óã  Excellent, well-structured application architecture\n‚óã  Public deployment on Render, Railway (or equivalent) fully functional\n‚óã  CI/CD runs on push/PR and deploys on success\n‚óã  Excellent documentation of design choices.\n‚óã  Excellent evaluation results, which includes groundedness, citation\n\naccuracy, and latency\n\n‚óã  Excellent, clear demo of features, design and evaluation",
    "vector_index": 49
  },
  {
    "doc_id": "rubric",
    "chunk_id": 12,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óè  Addresses MOST of the project requirements, but not limited to:\n\n‚óã  Excellent RAG application with correct responses with generally\n\nmatching citations, ingest and indexing works\n‚óã  Very good, well-structured application architecture\n‚óã  Public deployment on Render, Railway (or equivalent) almost fully\n\nfunctional\n\n‚óã  CI/CD runs on push/PR and deploys on success\n‚óã  Very good documentation of design choices.\n‚óã  Very good evaluation results which includes groundedness, citation\n\naccuracy, and latency\n\n‚óã  Very good, clear demo of features, design and evaluation",
    "vector_index": 50
  },
  {
    "doc_id": "rubric",
    "chunk_id": 13,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óè  Addresses SOME of the project requirements, but not limited to:\n\n‚óã  Very good RAG application with mainly correct responses with\n\ngenerally matching citations, ingest and indexing works\n\n‚óã  Good, well-structured application architecture\n‚óã  Public deployment on Render, Railway (or equivalent) almost fully\n\nfunctional\n\n‚óã  CI/CD runs on push/PR and deploys on success\n‚óã  Good documentation of design choices.\n\n4\n\n3\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21                                        6\n\n\n\n\n\n\n\nAI Engineering Project\n\n‚óã  Good evaluation results which includes most of groundedness,\n\ncitation accuracy, and latency\n\n‚óã  Good, clear demo of features, design and evaluation.",
    "vector_index": 51
  },
  {
    "doc_id": "rubric",
    "chunk_id": 14,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "‚óè  Addresses FEW of the project requirements, but not limited to:\n\n‚óã  Passable RAG application with limited correct responses with few\n\nmatching citations, ingest and indexing works partially\n\n‚óã  Passable application architecture\n‚óã  Public deployment on Render, Railway (or equivalent) not fully\n\nfunctional\n\n‚óã  CI/CD runs on push/PR and deploys on success\n‚óã  Passable documentation of design choices.\n‚óã  Passable evaluation results which includes only some of\n\ngroundedness, citation accuracy, and latency\n‚óã  Passable demo of features, design and evaluation\n\n‚óè  Addresses the project but MOST of the project requirements are missing,",
    "vector_index": 52
  },
  {
    "doc_id": "rubric",
    "chunk_id": 15,
    "source_file": "rubric.jsonl",
    "method": "heading",
    "params": {
      "mode": "heuristic",
      "min_heading_gap": 1,
      "max_chunk_len": null
    },
    "source_hash": "1a2f63be566b84ce4bd4c1cfa296d6b488cbb0d7b72a37d9fe0a9d1a11018906",
    "text": "but not limited to:\n\nIncomplete app; not deployed,\n\n‚óã\n‚óã  No CI/CD,\n‚óã  No to very limited evaluation\n‚óã  No design documentation\n‚óã  No demo of application\n\n‚óè  The student either did not complete the assignment, plagiarized all or part\n\nof the assignment, or completely failed to address the project requirements.\n\n2\n\n1\n\n0\n\n ¬© 2025 Quantic Holdings, Inc. All rights reserved.      6/23/21                                        7",
    "vector_index": 53
  }
]